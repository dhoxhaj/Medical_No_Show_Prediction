{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OuoGK86yOlb4"
      },
      "source": [
        "### **Dataset:** Medical Appointment No-Shows"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8cDEi2g3QZxb"
      },
      "source": [
        "# Project Definition and Scope"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KEEI-BksQjl8"
      },
      "source": [
        "The goal of this project is to build a machine learning model to predict whether a patient will show up for their scheduled medical appointment. The dataset used comes from a Brazilian public health system and contains over 110,527 medical appointments, each with various demographic, medical, and scheduling-related features.\n",
        "\n",
        "Missed medical appointments — known as *no-shows* — are a significant issue for healthcare providers. They result in lost time, wasted resources, and delayed treatment. Accurately predicting no-shows allows clinics to proactively intervene, such as by sending reminders, rescheduling, or double-booking slots.\n",
        "\n",
        "###  Objective\n",
        "- Analyze and preprocess the Medical Appointment No-Shows dataset.\n",
        "- Perform feature engineering to create meaningful predictors.\n",
        "- Train and evaluate multiple machine learning models.\n",
        "- Identify the best-performing model for predicting appointment no-shows.\n",
        "\n",
        "###  Target Definition\n",
        "The original `No-show` column contains:\n",
        "- `\"No\"` → Patient **showed up**\n",
        "- `\"Yes\"` → Patient **did not show up**\n",
        "\n",
        "To reduce confusion, we rename this column to `NoShow` and convert it to binary:\n",
        "- `0` → Patient showed up\n",
        "- `1` → Patient missed the appointment (positive class)\n",
        "\n",
        "This binary label will serve as the target variable for the classification models.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lRb6mJ7cSBaf"
      },
      "source": [
        "# Data Collection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cOcvs3iYTPhF"
      },
      "source": [
        "- The dataset can be downloaded online or imported in code from Kaggle."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0m-wSCy-Tj1J"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Set the path of the file\n",
        "data_path = \"/content/KaggleV2-May-2016.csv\"\n",
        "\n",
        "# Load the data into a pandas DataFrame\n",
        "data = pd.read_csv(data_path)\n",
        "\n",
        "# Display the shape of the DataFrame\n",
        "print(f\"Data loaded successfully with shape: {data.shape}\")\n",
        "\n",
        "# Print a view of the dataset\n",
        "data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5L1rDuwpfpLl"
      },
      "source": [
        "## Basic Overview of the Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qenwETPrfxXA"
      },
      "source": [
        "- Determine the number of instances (rows) and columns (features)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Van9XCwOf5Wm"
      },
      "outputs": [],
      "source": [
        "# 1. Determine the number of instances (rows) and columns (features)\n",
        "num_rows, num_cols = data.shape\n",
        "print(f\"Number of instances (rows): {num_rows}\")\n",
        "print(f\"Number of features (columns): {num_cols}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GVj_G-JdgeL8"
      },
      "source": [
        "- Display the first 5 rows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DMrCeZEcgh8q"
      },
      "outputs": [],
      "source": [
        "# 2. Display the first 5 rows of the dataset\n",
        "print(\"\\nFirst 5 rows of the dataset:\")\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E6atHeDLglXq"
      },
      "source": [
        "- Duisplay the last 5 rows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RV85m7pqgn8_"
      },
      "outputs": [],
      "source": [
        "# 3. Display the last 5 rows of the dataset\n",
        "print(\"\\nLast 5 rows of the dataset:\")\n",
        "data.tail()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xuYgdY1PhC5z"
      },
      "source": [
        "## General Dataset Information"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uSVgO5hYhFqp"
      },
      "outputs": [],
      "source": [
        "# General information about the dataset\n",
        "data.info()\n",
        "\n",
        "print(\"\\n\\n\")\n",
        "\n",
        "# Summary statistics for numerical columns\n",
        "data.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qZzGGJO8h1-J"
      },
      "source": [
        "###  Dataset Overview and Summary Statistics\n",
        "\n",
        "The dataset contains **110,527 records** and **14 columns**, with **no missing values** across any of the features.\n",
        "\n",
        "#### Data Types\n",
        "- **Float64**: 1 column (`PatientId`)\n",
        "- **Int64**: 8 columns (`AppointmentID`, `Age`, `Scholarship`, `Hipertension`, `Diabetes`, `Alcoholism`, `Handcap`, `SMS_received`)\n",
        "- **Object (string)**: 5 columns (`Gender`, `ScheduledDay`, `AppointmentDay`, `Neighbourhood`, `No-show`)\n",
        "\n",
        "####  Summary Statistics Highlights (`.describe()`):\n",
        "- **Age** ranges from **-1 to 115**. A minimum age of `-1` is invalid and will require cleaning.\n",
        "- **Binary columns** (0 or 1): `Scholarship`, `Hipertension`, `Diabetes`, `Alcoholism`, `SMS_received`  \n",
        "  These can be treated as categorical indicators.\n",
        "- **Handcap** ranges from 0 to 4, but most values are 0 — treatable as ordinal or binary after inspection.\n",
        "- **High cardinality column**:  \n",
        "  `PatientId` has many unique values, likely acting as an identifier and not useful for prediction.  \n",
        "  `AppointmentID` also shows wide numeric spread and can be excluded from modeling.\n",
        "\n",
        "####  Notes\n",
        "- The `ScheduledDay` and `AppointmentDay` columns are currently stored as text and will need to be converted to datetime for further analysis.\n",
        "- The `No-show` column contains `\"Yes\"`/`\"No\"` and will be converted to a binary `NoShow` column (1 = missed, 0 = showed up).\n",
        "\n",
        "Overall, the dataset is clean in terms of null values but contains some anomalies (like negative age) and high-cardinality identifiers that must be addressed before modeling.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "coH3j-yMiufH"
      },
      "source": [
        "## Data quality checks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tqYecoS8iyB8"
      },
      "outputs": [],
      "source": [
        "# Check for missing/null values\n",
        "missing_values = data.isnull().sum()\n",
        "print(\"Missing values per column:\\n\")\n",
        "print(missing_values)\n",
        "\n",
        "# Check for negative age values\n",
        "negative_ages = data[data['Age'] < 0]\n",
        "print(f\"\\nNumber of rows with negative age: {len(negative_ages)}\")\n",
        "\n",
        "# Check unique values in 'Handcap'\n",
        "print(\"\\nUnique values in 'Handcap':\", data['Handcap'].unique())\n",
        "\n",
        "# Check for values greater than expected (e.g., > 4)\n",
        "out_of_range_handcap = data[data['Handcap'] > 4]\n",
        "print(f\"Rows with out-of-range 'Handcap' values (>4): {len(out_of_range_handcap)}\")\n",
        "out_of_range_handcap.head()\n",
        "\n",
        "# Check for exact duplicate rows\n",
        "duplicate_count = data.duplicated().sum()\n",
        "print(f\"\\nNumber of exact duplicate rows: {duplicate_count}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q575g61WkF8n"
      },
      "source": [
        "### Data Quality Checks Summary\n",
        "\n",
        "As observed in the earlier `.info()` step, there are no missing values in any of the 14 columns — confirmed again using `.isnull().sum()`.\n",
        "\n",
        "- Age: One row contains an invalid value of `-1`, confirming the previously noted anomaly.\n",
        "- Handcap: Values range from 0 to 4. No out-of-range values (>4) are present.\n",
        "- Duplicate Rows: There are no exact duplicate rows in the dataset.\n",
        "\n",
        "These checks confirm the dataset is structurally clean, with only one clear anomaly (negative age) that should be handled during preprocessing.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xurjGiGhkb9B"
      },
      "source": [
        "## Feature Uniqueness Exploration\n",
        "- Categorical Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z9EKrgzxki_W"
      },
      "outputs": [],
      "source": [
        "# Quick view of unique values per column\n",
        "data.nunique()\n",
        "\n",
        "# View unique values for selected categorical features\n",
        "for col in ['Gender', 'Neighbourhood', 'No-show']:\n",
        "    print(f\"\\n{col} - unique values:\\n{data[col].value_counts()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QCSrUwcVk89p"
      },
      "source": [
        "\n",
        "\n",
        "While previous steps focused primarily on numerical features, this step inspects the unique values of key **categorical variables**.\n",
        "\n",
        "- **Gender**: Two categories — `F` (female) and `M` (male), with females making up the majority.\n",
        "- **Neighbourhood**: Contains 81 unique values, indicating high cardinality. This will require encoding (e.g., one-hot or target encoding) during preprocessing.\n",
        "- **No-show**: Two values — `\"No\"` (patient showed up) and `\"Yes\"` (patient missed). These will be converted to binary (`0` and `1`) for modeling.\n",
        "\n",
        "This step is essential to confirm category distributions, detect imbalances, and inform appropriate encoding strategies for categorical features.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f60iob1NmiJ1"
      },
      "source": [
        "## Target Variable Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lwV4y5C5mlkV"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Check value counts for the original 'No-show' column\n",
        "print(\"Value counts:\\n\")\n",
        "print(data['No-show'].value_counts())\n",
        "\n",
        "print(\"\\n\\n\")\n",
        "\n",
        "# Plot class distribution\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.countplot(x='No-show', data=data, palette='pastel')\n",
        "plt.title(\"No-show Class Distribution\")\n",
        "plt.xlabel(\"No-show (Yes = Missed, No = Attended)\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p9XUHjzpnEmR"
      },
      "source": [
        "### Target Variable Analysis – No-show Distribution\n",
        "\n",
        "The `No-show` column shows a clear class imbalance:\n",
        "\n",
        "- **\"No\"** (patient showed up): 88,208 instances (~80%)\n",
        "- **\"Yes\"** (patient missed appointment): 22,319 instances (~20%)\n",
        "\n",
        "This imbalance is also visible in the bar chart.\n",
        "\n",
        "The imbalance will be considered when selecting evaluation metrics and will be addressed during preprocessing\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lxR9RG5Loosa"
      },
      "source": [
        "# Feature Engineering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x9y9RwQWrDAE"
      },
      "source": [
        "To enhance the predictive power of the dataset, several new features were engineered based on appointment scheduling dates and time intervals. These features aim to capture behavioral patterns and scheduling dynamics that may influence whether a patient attends their appointment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PHTU2GuZstnj"
      },
      "source": [
        "### DaysBetween  \n",
        "**Description**: Number of days between when the appointment was scheduled and when it was held.  \n",
        "**Purpose**: Captures the waiting time for each patient, which may influence their likelihood of showing up. Longer delays may increase the risk of no-shows.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lThT5FtGos4t"
      },
      "outputs": [],
      "source": [
        "# Convert to datetime (if not already)\n",
        "data['ScheduledDay'] = pd.to_datetime(data['ScheduledDay']).dt.date\n",
        "data['AppointmentDay'] = pd.to_datetime(data['AppointmentDay']).dt.date\n",
        "\n",
        "# Convert back to datetime (optional, for subtraction)\n",
        "data['ScheduledDay'] = pd.to_datetime(data['ScheduledDay'])\n",
        "data['AppointmentDay'] = pd.to_datetime(data['AppointmentDay'])\n",
        "\n",
        "# Now calculate DaysBetween\n",
        "data['DaysBetween'] = (data['AppointmentDay'] - data['ScheduledDay']).dt.days\n",
        "\n",
        "data['DaysBetween']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "znoFPsKWsWdf"
      },
      "source": [
        " DaysBetween Calculation – Explanation\n",
        "\n",
        "1. **Convert to Date Only**:  \n",
        "   `ScheduledDay` and `AppointmentDay` are first converted to contain only the date (removing the time component) to avoid negative day differences caused by time-of-day differences.\n",
        "\n",
        "2. **Reconvert to Datetime**:  \n",
        "   The `.dt.date` format is converted back to full datetime so subtraction can be performed correctly.\n",
        "\n",
        "3. **Calculate DaysBetween**:  \n",
        "   The difference in days between the appointment date and the scheduling date is computed using `.dt.days`.\n",
        "\n",
        "This ensures that appointments scheduled and held on the same calendar day have `DaysBetween = 0`, avoiding rounding errors like `-1`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "peYBN9Odswfx"
      },
      "source": [
        "### ScheduledWeekday  \n",
        "**Description**: Indicates the day of the week (0 = Monday, ..., 6 = Sunday) on which the appointment was scheduled.  \n",
        "**Purpose**: Helps capture booking behavior patterns. Patients scheduling appointments earlier in the week may be more intentional or organized, which could influence attendance rates.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zbs5f967tCZa"
      },
      "outputs": [],
      "source": [
        "# ScheduledWeekday: weekday when the appointment was scheduled\n",
        "data['ScheduledWeekday'] = data['ScheduledDay'].dt.dayofweek\n",
        "\n",
        "data['ScheduledWeekday']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gw5BDRJwtN7V"
      },
      "source": [
        "### AppointmentWeekday  \n",
        "**Description**: Indicates the day of the week on which the appointment is scheduled to occur (0 = Monday, ..., 6 = Sunday).  \n",
        "**Purpose**: No-show behavior may vary by day. For instance, patients may be more likely to skip appointments on Mondays or Fridays due to routine disruptions or long weekends.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_SEMmxvftOqz"
      },
      "outputs": [],
      "source": [
        "# AppointmentWeekday: weekday when the appointment takes place\n",
        "data['AppointmentWeekday'] = data['AppointmentDay'].dt.dayofweek\n",
        "\n",
        "data['AppointmentWeekday']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xD1eoCfHtd4q"
      },
      "source": [
        "### IsWeekendAppointment  \n",
        "**Description**: A boolean feature indicating whether the appointment is scheduled on a weekend (Saturday = 5, Sunday = 6).  \n",
        "**Purpose**: Weekend appointments may affect attendance patterns due to differences in availability, responsibilities, or access to transportation compared to weekdays.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wp_Aa0yPteRV"
      },
      "outputs": [],
      "source": [
        "# IsWeekendAppointment: True if appointment is on Saturday or Sunday\n",
        "data['IsWeekendAppointment'] = data['AppointmentWeekday'].isin([5, 6])\n",
        "\n",
        "data['IsWeekendAppointment']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2FHWzd2tuiZx"
      },
      "source": [
        "### Feature Engineering – Pros and Cons\n",
        "\n",
        "**Pros:**\n",
        "- **Domain-driven**: Features like `DaysBetween` and `AppointmentWeekday` are based on real-world patient scheduling behavior, making them meaningful and interpretable.\n",
        "- **Temporal and behavioral context**: The features capture both how far in advance appointments are booked and patterns across different days of the week.\n",
        "- **Model compatibility**: A mix of continuous and categorical features allows flexibility across various machine learning models.\n",
        "\n",
        "**Cons:**\n",
        "- **Redundancy risk**: Some features (e.g., `AppointmentWeekday` and `IsWeekendAppointment`) may convey overlapping information and require correlation checks.\n",
        "- **Encoding overhead**: Categorical features such as weekdays must be encoded before modeling, adding extra preprocessing steps.\n",
        "- **No historical behavior**: The features do not include patient history (e.g., past no-shows), which could be a strong predictor but is not available in this dataset.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "moSmoW6E_9Cd"
      },
      "source": [
        "# Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wDIR-H50BBdW"
      },
      "outputs": [],
      "source": [
        "# Make a working copy of the data to preserve the original dataset\n",
        "df = data.copy(deep=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ywCrJo2FBH13"
      },
      "source": [
        "- Convert Dates to datetime\n",
        "- Convert and Rename Target Variable\n",
        "- Remove Anomalies\n",
        "- Drop ID Columns and Neighboorhourhood"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dN8QswSMBKdL"
      },
      "outputs": [],
      "source": [
        "# Convert ScheduledDay and AppointmentDay to datetime (remove time)\n",
        "df['ScheduledDay'] = pd.to_datetime(df['ScheduledDay']).dt.date\n",
        "df['AppointmentDay'] = pd.to_datetime(df['AppointmentDay']).dt.date\n",
        "\n",
        "# Convert back to full datetime to allow subtraction\n",
        "df['ScheduledDay'] = pd.to_datetime(df['ScheduledDay'])\n",
        "df['AppointmentDay'] = pd.to_datetime(df['AppointmentDay'])\n",
        "\n",
        "# Replace string labels with binary values\n",
        "df['No-show'] = df['No-show'].replace({'No': 0, 'Yes': 1})\n",
        "\n",
        "# Remove invalid age values\n",
        "df = df[df['Age'] >= 0]\n",
        "\n",
        "# Remove non-predictive identifiers\n",
        "df.drop(['PatientId', 'AppointmentID',\"Neighbourhood\"], axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GcmpkhiYCYYf"
      },
      "source": [
        "- Normalize Continuous Features\n",
        "- Encode Binary Categorical Features\n",
        "- One-Hot Encode Multi-class Categorical Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hr-VMlxvCe9X"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# -----\n",
        "# Normalizing Continuous Features\n",
        "\n",
        "# Create a scaler instance\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "# Normalize 'Age' and 'DaysBetween' (apply after DaysBetween has been created)\n",
        "df.loc[:, ['Age', 'DaysBetween']] = scaler.fit_transform(df[['Age', 'DaysBetween']])\n",
        "\n",
        "# -----\n",
        "# Encode Binary Categorical Features\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# List of binary categorical features\n",
        "binary_cols = ['Gender', 'Scholarship', 'Hipertension', 'Diabetes', 'Alcoholism', 'SMS_received', 'IsWeekendAppointment']\n",
        "\n",
        "# Apply label encoding (0 = No, 1 = Yes or Female/Male)\n",
        "le = LabelEncoder()\n",
        "for col in binary_cols:\n",
        "    df.loc[:, col] = le.fit_transform(df[col])\n",
        "\n",
        "\n",
        "# -----\n",
        "# One-Hot Encode Multi-class Categorical Features\n",
        "\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# Columns to one-hot encode (e.g., weekday features)\n",
        "onehot_cols = ['ScheduledDay', 'AppointmentDay']\n",
        "\n",
        "# Initialize encoder\n",
        "encoder = OneHotEncoder(sparse_output=False, drop='first')\n",
        "\n",
        "# Fit and transform\n",
        "encoded = encoder.fit_transform(df[onehot_cols])\n",
        "\n",
        "# Create DataFrame with encoded columns\n",
        "encoded_df = pd.DataFrame(encoded, columns=encoder.get_feature_names_out(onehot_cols), index=df.index)\n",
        "\n",
        "# Drop original columns and append encoded ones\n",
        "df.drop(columns=onehot_cols, inplace=True)\n",
        "df = pd.concat([df, encoded_df], axis=1)\n",
        "\n",
        "# Move the target variable 'No-show' to the end of the DataFrame\n",
        "target = df.pop('No-show')\n",
        "df['No-show'] = target\n",
        "\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_ryxbIhHJwO"
      },
      "source": [
        "### SMOTE Application\n",
        "\n",
        "In this step, we split the dataset into training and testing sets using an 80/20 ratio with stratification to preserve the original class distribution.\n",
        "\n",
        "SMOTE (Synthetic Minority Oversampling Technique) is applied **only to the training set** to generate synthetic examples of the minority class (missed appointments). This prevents data leakage and ensures the model does not learn from artificially created patterns that exist in the test set.\n",
        "\n",
        "By training on a balanced dataset and evaluating on the original, imbalanced test set, we ensure a fair and realistic assessment of model performance.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C6y6vVHHHLzy"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 1. Separate features and target\n",
        "X = df.drop('No-show', axis=1)\n",
        "y = df['No-show']\n",
        "\n",
        "# 2. Split into training and testing sets (stratify to maintain imbalance in test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, stratify=y, random_state=42\n",
        ")\n",
        "\n",
        "# 3. Apply SMOTE to training set\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "# 4. Visualize class balance in the resampled training set\n",
        "sns.countplot(x=y_train_smote)\n",
        "plt.title(\"Class Distribution After SMOTE (Training Set)\")\n",
        "plt.xlabel(\"No-show (0 = Showed up, 1 = Missed)\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n\\n\\n\")\n",
        "\n",
        "# Original training and testing set sizes\n",
        "print(f\"Original training set size: {X_train.shape[0]} rows\")\n",
        "print(f\"Original testing set size: {X_test.shape[0]} rows\")\n",
        "\n",
        "# After SMOTE\n",
        "print(f\"Training set size after SMOTE: {X_train_smote.shape[0]} rows\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OPjVHhkUJiGq"
      },
      "source": [
        "The training set was balanced using SMOTE to address class imbalance. Originally, the training set had 88,420 samples, which increased to 141,130 after synthetic examples were added. The class distribution is now even (0 = showed up, 1 = missed), as shown in the bar plot, helping improve model performance and fairness."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
